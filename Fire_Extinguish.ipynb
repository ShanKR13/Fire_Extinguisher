{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cdcd280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Input\n",
    "from scikeras.wrappers import KerasClassifier  # <-- modern wrapper\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Load dataset\n",
    "# -------------------------------\n",
    "data = pd.read_csv(\n",
    "    r\"E:\\Proj\\FireExtinguisher\\acoustic.csv\"\n",
    ")\n",
    "\n",
    "# Encode target if not numeric\n",
    "if data[\"STATUS\"].dtype == \"object\":\n",
    "    le = LabelEncoder()\n",
    "    data[\"STATUS\"] = le.fit_transform(data[\"STATUS\"])\n",
    "\n",
    "# Features & target\n",
    "X = data.drop(\"STATUS\", axis=1)\n",
    "y = data[\"STATUS\"]\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Preprocessing\n",
    "# -------------------------------\n",
    "numerical_features = [\"SIZE\", \"DISTANCE\", \"DECIBEL\", \"AIRFLOW\", \"FREQUENCY\"]\n",
    "categorical_features = [\"FUEL\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"num\", StandardScaler(), numerical_features),\n",
    "        (\"cat\", OneHotEncoder(), categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# -------------------------------\n",
    "# 3. ANN/DNN creators\n",
    "# -------------------------------\n",
    "def create_ann():\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train_processed.shape[1],)))  # modern input layer\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dense(32, activation=\"relu\"))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "def create_dnn():\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train_processed.shape[1],)))  # modern input layer\n",
    "    model.add(Dense(128, activation=\"relu\"))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dense(32, activation=\"relu\"))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "# -------------------------------\n",
    "# 4. Classical Models with tuning\n",
    "# -------------------------------\n",
    "# k-NN\n",
    "param_grid_knn = {\n",
    "    \"n_neighbors\": [5, 7, 9],\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"metric\": [\"euclidean\"],\n",
    "}\n",
    "grid_knn = GridSearchCV(KNeighborsClassifier(), param_grid_knn, cv=5)\n",
    "grid_knn.fit(X_train_processed, y_train)\n",
    "best_knn = grid_knn.best_estimator_\n",
    "\n",
    "# Random Forest\n",
    "param_grid_rf = {\n",
    "    \"n_estimators\": [200],\n",
    "    \"max_depth\": [20],\n",
    "    \"min_samples_split\": [5],\n",
    "}\n",
    "grid_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=5)\n",
    "grid_rf.fit(X_train_processed, y_train)\n",
    "best_rf = grid_rf.best_estimator_\n",
    "\n",
    "# -------------------------------\n",
    "# 5. ANN & DNN Wrappers\n",
    "# -------------------------------\n",
    "ann = KerasClassifier(\n",
    "    model=create_ann, epochs=50, batch_size=32, verbose=0, random_state=42\n",
    ")\n",
    "dnn = KerasClassifier(\n",
    "    model=create_dnn, epochs=50, batch_size=32, verbose=0, random_state=42\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Stacking (includes ANN & DNN)\n",
    "# -------------------------------\n",
    "stacking = StackingClassifier(\n",
    "    estimators=[\n",
    "        (\"knn\", best_knn),\n",
    "        (\"rf\", best_rf),\n",
    "        (\"ann\", ann),\n",
    "        (\"dnn\", dnn),\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(),\n",
    "    passthrough=False\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Evaluation\n",
    "# -------------------------------\n",
    "models = {\n",
    "    \"k-NN\": best_knn,\n",
    "    \"Random Forest\": best_rf,\n",
    "    \"ANN\": ann,\n",
    "    \"DNN\": dnn,\n",
    "    \"Stacking\": stacking,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "353ece2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN CV Accuracy: 0.9600\n",
      "Random Forest CV Accuracy: 0.9644\n",
      "ANN CV Accuracy: 0.9553\n",
      "DNN CV Accuracy: 0.9637\n",
      "Stacking CV Accuracy: 0.9716\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(\n",
    "        model, X_train_processed, y_train, cv=3, scoring=\"accuracy\"\n",
    "    )  # reduce CV for speed\n",
    "    results[name] = scores.mean()\n",
    "    print(f\"{name} CV Accuracy: {scores.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "962ee85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "k-NN Test Accuracy: 0.9616\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1752\n",
      "           1       0.96      0.96      0.96      1737\n",
      "\n",
      "    accuracy                           0.96      3489\n",
      "   macro avg       0.96      0.96      0.96      3489\n",
      "weighted avg       0.96      0.96      0.96      3489\n",
      "\n",
      "\n",
      "Random Forest Test Accuracy: 0.9693\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1752\n",
      "           1       0.97      0.97      0.97      1737\n",
      "\n",
      "    accuracy                           0.97      3489\n",
      "   macro avg       0.97      0.97      0.97      3489\n",
      "weighted avg       0.97      0.97      0.97      3489\n",
      "\n",
      "\n",
      "ANN Test Accuracy: 0.9602\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1752\n",
      "           1       0.96      0.96      0.96      1737\n",
      "\n",
      "    accuracy                           0.96      3489\n",
      "   macro avg       0.96      0.96      0.96      3489\n",
      "weighted avg       0.96      0.96      0.96      3489\n",
      "\n",
      "\n",
      "DNN Test Accuracy: 0.9665\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97      1752\n",
      "           1       0.97      0.96      0.97      1737\n",
      "\n",
      "    accuracy                           0.97      3489\n",
      "   macro avg       0.97      0.97      0.97      3489\n",
      "weighted avg       0.97      0.97      0.97      3489\n",
      "\n",
      "\n",
      "Stacking Test Accuracy: 0.9719\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1752\n",
      "           1       0.97      0.97      0.97      1737\n",
      "\n",
      "    accuracy                           0.97      3489\n",
      "   macro avg       0.97      0.97      0.97      3489\n",
      "weighted avg       0.97      0.97      0.97      3489\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    model.fit(X_train_processed, y_train)\n",
    "    y_pred = model.predict(X_test_processed)\n",
    "\n",
    "    # Convert keras float outputs to binary labels\n",
    "    if isinstance(model, KerasClassifier):\n",
    "        y_pred = (np.array(y_pred) > 0.5).astype(int).ravel()\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\n{name} Test Accuracy: {accuracy:.4f}\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f6f80d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
